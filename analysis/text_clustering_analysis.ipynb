{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YC Companies Text Clustering Analysis\n",
    "\n",
    "Cluster YC companies based on their text descriptions using OpenAI embeddings.\n",
    "\n",
    "**Approach:**\n",
    "1. Generate embeddings for company descriptions using OpenAI API\n",
    "2. Apply clustering algorithms (K-means, DBSCAN)\n",
    "3. Visualize clusters using dimensionality reduction (t-SNE, UMAP)\n",
    "4. Analyze cluster characteristics and patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úì Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Setup OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YC companies data\n",
    "data_path = '../data/2025-10-05-yc.companies.jl'\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "\n",
    "print(f\"‚úì Loaded {len(df):,} companies\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "# Create combined text for embedding\n",
    "df['combined_text'] = df.apply(\n",
    "    lambda x: f\"{x['company_name']}: {x['short_description']}. {x.get('long_description', '')} Tags: {', '.join(x['tags']) if isinstance(x['tags'], list) else ''}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to companies with meaningful descriptions\n",
    "df = df[df['short_description'].notna() & (df['short_description'].str.len() > 10)].copy()\n",
    "\n",
    "print(f\"\\n‚úì Filtered to {len(df):,} companies with descriptions\")\n",
    "print(f\"\\nExample text:\\n{df['combined_text'].iloc[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI client\n",
    "# Make sure to set your OPENAI_API_KEY environment variable\n",
    "# export OPENAI_API_KEY='your-api-key-here'\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è  OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"\\nSet it with: export OPENAI_API_KEY='your-key'\")\n",
    "    print(\"Or in notebook: import os; os.environ['OPENAI_API_KEY'] = 'your-key'\")\n",
    "    raise ValueError(\"Missing OpenAI API key\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"‚úì OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Embeddings\n",
    "\n",
    "Using OpenAI's `text-embedding-3-small` model (lower cost, good performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings in batches\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    \"\"\"\n",
    "    Get embeddings for texts in batches to handle rate limits.\n",
    "    \n",
    "    Note: OpenAI allows up to 3,000 RPM for text-embedding-3-small on free tier.\n",
    "    Adjust batch_size and add delays if you hit rate limits.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1} ({len(batch)} texts)...\")\n",
    "        \n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model\n",
    "            )\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "            # Return what we have so far\n",
    "            break\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "print(\"‚úì Embedding function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo purposes, let's use a sample\n",
    "# Remove this line to process all companies (will take longer and cost more)\n",
    "SAMPLE_SIZE = 500  # Set to None to process all companies\n",
    "\n",
    "if SAMPLE_SIZE:\n",
    "    df_sample = df.sample(n=min(SAMPLE_SIZE, len(df)), random_state=42).copy()\n",
    "    print(f\"‚ö†Ô∏è  Using sample of {len(df_sample):,} companies for demo\")\n",
    "else:\n",
    "    df_sample = df.copy()\n",
    "    print(f\"Processing all {len(df_sample):,} companies\")\n",
    "\n",
    "# Truncate text to avoid token limits (8191 tokens max for text-embedding-3-small)\n",
    "# Roughly 1 token = 4 characters, so limit to ~6000 chars to be safe\n",
    "texts = df_sample['combined_text'].apply(lambda x: x[:6000] if len(x) > 6000 else x).tolist()\n",
    "\n",
    "print(f\"\\nGenerating embeddings for {len(texts):,} companies...\")\n",
    "print(\"‚è±Ô∏è  This may take a few minutes depending on sample size and API rate limits\\n\")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = get_embeddings_batch(texts, batch_size=50)\n",
    "\n",
    "if len(embeddings) != len(texts):\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Got {len(embeddings)} embeddings for {len(texts)} texts\")\n",
    "    # Trim dataframe to match\n",
    "    df_sample = df_sample.iloc[:len(embeddings)].copy()\n",
    "\n",
    "# Add embeddings to dataframe\n",
    "df_sample['embedding'] = embeddings\n",
    "\n",
    "print(f\"\\n‚úì Generated {len(embeddings):,} embeddings\")\n",
    "print(f\"  Embedding dimension: {len(embeddings[0]) if embeddings else 0}\")\n",
    "print(f\"  Estimated cost: ${len(embeddings) * 0.00002:.4f} (at $0.02/1M tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to numpy array\n",
    "X = np.array(df_sample['embedding'].tolist())\n",
    "print(f\"Embedding matrix shape: {X.shape}\")\n",
    "\n",
    "# Normalize embeddings (helps with clustering)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"‚úì Embeddings normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Elbow Method - Find Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 21)\n",
    "\n",
    "print(\"Finding optimal K...\")\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"  K={k}: inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "plt.title('Elbow Method for Optimal K', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Look for the 'elbow' point where inertia starts decreasing more slowly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means with chosen K (adjust based on elbow plot)\n",
    "optimal_k = 8  # Adjust this based on elbow plot above\n",
    "\n",
    "print(f\"Applying K-means with K={optimal_k}...\")\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
    "df_sample['cluster_kmeans'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"‚úì K-means clustering complete\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df_sample['cluster_kmeans'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN (density-based clustering)\n",
    "print(\"Applying DBSCAN...\")\n",
    "dbscan = DBSCAN(eps=3.0, min_samples=5, metric='euclidean')\n",
    "df_sample['cluster_dbscan'] = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters = len(set(df_sample['cluster_dbscan'])) - (1 if -1 in df_sample['cluster_dbscan'].values else 0)\n",
    "n_noise = list(df_sample['cluster_dbscan']).count(-1)\n",
    "\n",
    "print(f\"‚úì DBSCAN clustering complete\")\n",
    "print(f\"  Clusters found: {n_clusters}\")\n",
    "print(f\"  Noise points: {n_noise}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df_sample['cluster_dbscan'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 t-SNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE for 2D visualization\n",
    "print(\"Applying t-SNE (this may take a few minutes)...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "df_sample['tsne_x'] = X_tsne[:, 0]\n",
    "df_sample['tsne_y'] = X_tsne[:, 1]\n",
    "\n",
    "print(\"‚úì t-SNE complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive t-SNE plot with K-means clusters\n",
    "fig = px.scatter(\n",
    "    df_sample,\n",
    "    x='tsne_x',\n",
    "    y='tsne_y',\n",
    "    color='cluster_kmeans',\n",
    "    hover_data=['company_name', 'short_description', 'batch', 'status'],\n",
    "    title=f't-SNE Visualization - K-means Clusters (K={optimal_k})',\n",
    "    labels={'cluster_kmeans': 'Cluster'},\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(height=700, width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive t-SNE plot with DBSCAN clusters\n",
    "fig = px.scatter(\n",
    "    df_sample,\n",
    "    x='tsne_x',\n",
    "    y='tsne_y',\n",
    "    color='cluster_dbscan',\n",
    "    hover_data=['company_name', 'short_description', 'batch', 'status'],\n",
    "    title='t-SNE Visualization - DBSCAN Clusters',\n",
    "    labels={'cluster_dbscan': 'Cluster (-1 = Noise)'},\n",
    "    color_continuous_scale='plasma'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(height=700, width=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster Analysis & Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each K-means cluster\n",
    "def analyze_cluster(df, cluster_id, cluster_col='cluster_kmeans'):\n",
    "    \"\"\"\n",
    "    Analyze characteristics of a cluster\n",
    "    \"\"\"\n",
    "    cluster_df = df[df[cluster_col] == cluster_id]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLUSTER {cluster_id} - {len(cluster_df)} companies ({len(cluster_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Top tags\n",
    "    all_tags = []\n",
    "    for tags in cluster_df['tags'].dropna():\n",
    "        if isinstance(tags, list):\n",
    "            all_tags.extend(tags)\n",
    "    \n",
    "    tag_counts = Counter(all_tags)\n",
    "    print(f\"\\nüìä Top Tags:\")\n",
    "    for tag, count in tag_counts.most_common(5):\n",
    "        print(f\"  ‚Ä¢ {tag}: {count} ({count/len(cluster_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Status distribution\n",
    "    print(f\"\\nüìà Status Distribution:\")\n",
    "    for status, count in cluster_df['status'].value_counts().head(3).items():\n",
    "        print(f\"  ‚Ä¢ {status}: {count} ({count/len(cluster_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Top locations\n",
    "    print(f\"\\nüìç Top Locations:\")\n",
    "    for loc, count in cluster_df['location'].value_counts().head(3).items():\n",
    "        print(f\"  ‚Ä¢ {loc}: {count}\")\n",
    "    \n",
    "    # Sample companies\n",
    "    print(f\"\\nüíº Sample Companies:\")\n",
    "    for idx, row in cluster_df.head(5).iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['company_name']}: {row['short_description'][:80]}...\")\n",
    "\n",
    "# Analyze all clusters\n",
    "for cluster_id in sorted(df_sample['cluster_kmeans'].unique()):\n",
    "    analyze_cluster(df_sample, cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cluster Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare cluster characteristics\n",
    "cluster_stats = df_sample.groupby('cluster_kmeans').agg({\n",
    "    'company_id': 'count',\n",
    "    'num_founders': 'mean',\n",
    "    'team_size': 'mean',\n",
    "    'year_founded': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "cluster_stats.columns = ['Size', 'Avg_Founders', 'Avg_Team_Size', 'Avg_Year_Founded']\n",
    "\n",
    "# Add success rate\n",
    "cluster_stats['Success_Rate'] = df_sample.groupby('cluster_kmeans').apply(\n",
    "    lambda x: (x['status'].str.contains('Public|Acquired', case=False, na=False).sum() / len(x) * 100)\n",
    ").round(1)\n",
    "\n",
    "print(\"\\nüìä CLUSTER COMPARISON:\")\n",
    "print(cluster_stats.to_string())\n",
    "\n",
    "# Visualize cluster sizes\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=cluster_stats.index,\n",
    "        y=cluster_stats['Size'],\n",
    "        text=cluster_stats['Size'],\n",
    "        textposition='outside',\n",
    "        marker_color='steelblue'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cluster Sizes',\n",
    "    xaxis_title='Cluster ID',\n",
    "    yaxis_title='Number of Companies',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustered data\n",
    "output_path = '../data/yc_companies_clustered.csv'\n",
    "df_sample[[\n",
    "    'company_id', 'company_name', 'short_description', 'batch', 'status', \n",
    "    'tags', 'cluster_kmeans', 'cluster_dbscan', 'tsne_x', 'tsne_y'\n",
    "]].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úì Saved clustered data to: {output_path}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä SUMMARY:\")\n",
    "print(f\"  Total companies analyzed: {len(df_sample):,}\")\n",
    "print(f\"  K-means clusters: {df_sample['cluster_kmeans'].nunique()}\")\n",
    "print(f\"  DBSCAN clusters: {df_sample['cluster_dbscan'].nunique()}\")\n",
    "print(f\"  Embedding dimension: {len(embeddings[0]) if embeddings else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "**Clustering Approach:**\n",
    "- Used OpenAI `text-embedding-3-small` for semantic embeddings\n",
    "- Applied K-means (parametric) and DBSCAN (density-based) clustering\n",
    "- Visualized with t-SNE dimensionality reduction\n",
    "\n",
    "**Findings:**\n",
    "- Companies naturally cluster by industry vertical and problem domain\n",
    "- Semantic similarity reveals non-obvious connections between companies\n",
    "- Some clusters show distinct characteristics (team size, location, success rate)\n",
    "\n",
    "**Limitations:**\n",
    "- Clustering quality depends on description text quality\n",
    "- Optimal K is subjective (use domain knowledge + elbow method)\n",
    "- t-SNE visualization is non-deterministic (different runs may vary)\n",
    "- Sample size affects cluster stability\n",
    "\n",
    "**Cost Considerations:**\n",
    "- `text-embedding-3-small`: ~$0.02 per 1M tokens\n",
    "- 500 companies ‚âà $0.01-0.02\n",
    "- 8,000 companies ‚âà $0.15-0.30\n",
    "\n",
    "---\n",
    "\n",
    "*Analysis powered by OpenAI embeddings and scikit-learn*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
